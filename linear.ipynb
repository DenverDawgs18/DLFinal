{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb92ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e16b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def get_data_loader(file, features, features_to_encode):\n",
    "    df = pd.read_csv(file)\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    df[[\"Episode_Length_minutes\"]] = imputer.fit_transform(df[[\"Episode_Length_minutes\"]])\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df[[\"Number_of_Ads\"]] = imputer.fit_transform(df[[\"Number_of_Ads\"]])\n",
    "    def one_hot(df, feature):\n",
    "        encoded = pd.get_dummies(df[[feature]])\n",
    "        result = pd.concat([df, encoded], axis=1)\n",
    "        result = result.drop([feature], axis=1)\n",
    "        return(result) \n",
    "    y = df[[\"Listening_Time_minutes\"]]\n",
    "    df = df[features]\n",
    "    for to_encode in features_to_encode:\n",
    "        df = one_hot(df, to_encode)\n",
    "    x = df\n",
    "    x_tensor = torch.from_numpy(x.to_numpy().astype(np.float32))\n",
    "    y_tensor = torch.from_numpy(y.to_numpy().astype(np.float32))\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "features=[\"Episode_Length_minutes\", \"Number_of_Ads\", \"Episode_Sentiment\"]\n",
    "features_to_encode = [\"Episode_Sentiment\"]\n",
    "train_dataloader = get_data_loader(\"train.csv\", \n",
    "    features=features,\n",
    "    features_to_encode=features_to_encode )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab8cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PodcastPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,  2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a6a7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_hat, y):\n",
    "    return torch.sqrt(F.mse_loss(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63abb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "lam = 0\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e26433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f1521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "PodcastPredictor                         --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Linear: 2-1                       1,536\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Linear: 2-3                       131,584\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       525,312\n",
      "│    └─ReLU: 2-6                         --\n",
      "│    └─Linear: 2-7                       2,099,200\n",
      "│    └─ReLU: 2-8                         --\n",
      "│    └─Linear: 2-9                       8,392,704\n",
      "│    └─ReLU: 2-10                        --\n",
      "│    └─Linear: 2-11                      8,390,656\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      2,098,176\n",
      "│    └─ReLU: 2-14                        --\n",
      "│    └─Linear: 2-15                      524,800\n",
      "│    └─ReLU: 2-16                        --\n",
      "│    └─Linear: 2-17                      131,328\n",
      "│    └─ReLU: 2-18                        --\n",
      "│    └─Linear: 2-19                      257\n",
      "=================================================================\n",
      "Total params: 22,295,553\n",
      "Trainable params: 22,295,553\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model = PodcastPredictor()\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79a580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Epoch 1, RMSE: 10.9282\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Epoch 2, RMSE: 10.7488\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Epoch 3, RMSE: 10.7059\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Epoch 4, RMSE: 10.6783\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Epoch 5, RMSE: 10.6660\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lam)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    i = 0\n",
    "    for xb, yb in train_dataloader:\n",
    "        y_hat = model(xb)\n",
    "        loss = rmse_loss(y_hat, yb)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "    print(f\"Epoch {epoch+1}, RMSE: {total_loss / len(train_dataloader.dataset):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad26a02d-cbcf-40fe-9faf-e79839992f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6ccad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model1.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b4b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def get_test_loader(file, features, features_to_encode):\n",
    "    df = pd.read_csv(file)\n",
    "    def one_hot(df, feature):\n",
    "        encoded = pd.get_dummies(df[[feature]])\n",
    "        result = pd.concat([df, encoded], axis=1)\n",
    "        result = result.drop([feature], axis=1)\n",
    "        return(result) \n",
    "    df = df[features]\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    df[[\"Episode_Length_minutes\"]] = imputer.fit_transform(df[[\"Episode_Length_minutes\"]])\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df[[\"Number_of_Ads\"]] = imputer.fit_transform(df[[\"Number_of_Ads\"]])\n",
    "    for to_encode in features_to_encode:\n",
    "        df = one_hot(df, to_encode)\n",
    "    x = df\n",
    "    x_tensor = torch.from_numpy(x.to_numpy().astype(np.float32))\n",
    "    y_tensor = torch.from_numpy(np.zeros(250000).astype(np.float32))\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    return dataloader\n",
    "\n",
    "features=[\"Episode_Length_minutes\", \"Number_of_Ads\", \"Episode_Sentiment\"]\n",
    "features_to_encode = [\"Episode_Sentiment\"]\n",
    "test_dataloader = get_test_loader(\"test.csv\", \n",
    "    features=features,\n",
    "    features_to_encode=features_to_encode )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea5e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "\n",
    "id = 750000\n",
    "rows = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (xb, yb) in enumerate(test_dataloader):\n",
    "        y_hat = model(xb)\n",
    "        for pred in y_hat:\n",
    "            rows.append([id, pred.item()])\n",
    "            id += 1\n",
    "        if (i+1) % 25000 == 0:\n",
    "            print(f\"Processed {i+1} batches\")\n",
    "\n",
    "with open(\"submission.csv\", \"w\", newline='') as f:\n",
    "    writer_object = writer(f)\n",
    "    writer_object.writerow([\"id\", \"prediction\"])  # Add header\n",
    "    writer_object.writerows(rows)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
