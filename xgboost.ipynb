{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "import matplotlib as plt \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e780b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature definitions\n",
    "features = [\"Episode_Length_minutes\", \"Number_of_Ads\", \"Host_Popularity_percentage\",\n",
    "            \"Guest_Popularity_percentage\", \"Episode_Sentiment\", \"Publication_Day\",\n",
    "            \"Publication_Time\", \"Genre\", \"Podcast_Name\"]\n",
    "\n",
    "features_to_encode = [\"Episode_Sentiment\", \"Publication_Day\", \"Publication_Time\", \"Genre\", \"Podcast_Name\"]\n",
    "\n",
    "# Label encoders\n",
    "encoders = {feature: LabelEncoder() for feature in features_to_encode}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acf5ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlr = 0.375\\nn_estimators = 1200\\nmax_bin = 1024\\n\\ncommon_params = {\\n    \"objective\": \"reg:squarederror\",\\n    \"n_estimators\": n_estimators,\\n    \"max_depth\": 6,\\n    \"learning_rate\": lr,\\n    \"max_bin\": max_bin,\\n    \"verbosity\": 0\\n}\\n\\nmodels = []\\nfor _ in range(10):\\n    model = xgb.XGBRegressor(**common_params)\\n    model.fit(x, y, eval_set=[(x, y)], verbose=True)\\n    models.append(model)\\n\\nmodel1, model2, model3, model4, model5, model6, model7, model8, model9, model10 = models\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lr = 0.375\n",
    "n_estimators = 1200\n",
    "max_bin = 1024\n",
    "\n",
    "common_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": lr,\n",
    "    \"max_bin\": max_bin,\n",
    "    \"verbosity\": 0\n",
    "}\n",
    "\n",
    "models = []\n",
    "for _ in range(10):\n",
    "    model = xgb.XGBRegressor(**common_params)\n",
    "    model.fit(x, y, eval_set=[(x, y)], verbose=True)\n",
    "    models.append(model)\n",
    "\n",
    "model1, model2, model3, model4, model5, model6, model7, model8, model9, model10 = models\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6eac799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, is_train=True):\n",
    "    df[\"Episode_Title\"] = df[\"Episode_Title\"].str[8:]\n",
    "\n",
    "    # Impute missing values\n",
    "    for col in [\"Episode_Length_minutes\", \"Guest_Popularity_percentage\", \"Number_of_Ads\"]:\n",
    "        df[[col]] = SimpleImputer(strategy=\"median\").fit_transform(df[[col]])\n",
    "\n",
    "    # Weekend flag\n",
    "\n",
    "    # Label encode categorical variables\n",
    "    for feature in features_to_encode:\n",
    "        if is_train:\n",
    "            df[feature] = encoders[feature].fit_transform(df[feature])\n",
    "        else:\n",
    "            df[feature] = encoders[feature].transform(df[feature])\n",
    "\n",
    "    # Feature engineering\n",
    "    df[\"Ads_Per_Minute\"] = df[\"Number_of_Ads\"] / df[\"Episode_Length_minutes\"]\n",
    "    df[\"People_Popularity\"] = df[\"Host_Popularity_percentage\"] + df[\"Guest_Popularity_percentage\"]\n",
    "    df[\"Linear\"] = df[\"Episode_Length_minutes\"] * 0.728\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c83c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered = [\"Ads_Per_Minute\", \"People_Popularity\", \"Linear\"]\n",
    "def get_train_data(file):\n",
    "    df = pd.read_csv(file)\n",
    "    y = df[[\"Listening_Time_minutes\"]].to_numpy().astype(np.float32)\n",
    "    df = preprocess(df, is_train=True)\n",
    "    x = df[features + engineered].to_numpy().astype(np.float32)\n",
    "    return x, y\n",
    "\n",
    "def get_test_data(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df = preprocess(df, is_train=False)\n",
    "    x = df[features + engineered].to_numpy().astype(np.float32)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b31eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_train_data(\"train.csv\")\n",
    "X_test = get_test_data(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7afc6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"max_bin\": 1024,\n",
    "    \"num_leaves\": 1024,\n",
    "    \"max_depth\": -1,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"random_state\": 42\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6221\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 45.447808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:374: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning(\"Converting column-vector to 1d array\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 13.0082\tvalid_0's l2: 169.212\n",
      "[200]\tvalid_0's rmse: 12.8625\tvalid_0's l2: 165.443\n",
      "[300]\tvalid_0's rmse: 12.822\tvalid_0's l2: 164.404\n",
      "[400]\tvalid_0's rmse: 12.8002\tvalid_0's l2: 163.845\n",
      "[500]\tvalid_0's rmse: 12.7824\tvalid_0's l2: 163.39\n",
      "[600]\tvalid_0's rmse: 12.7666\tvalid_0's l2: 162.985\n",
      "[700]\tvalid_0's rmse: 12.7565\tvalid_0's l2: 162.728\n",
      "[800]\tvalid_0's rmse: 12.7465\tvalid_0's l2: 162.473\n",
      "[900]\tvalid_0's rmse: 12.7379\tvalid_0's l2: 162.255\n",
      "[1000]\tvalid_0's rmse: 12.7306\tvalid_0's l2: 162.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6221\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 45.421359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\lightgbm\\basic.py:374: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning(\"Converting column-vector to 1d array\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 13.0451\tvalid_0's l2: 170.174\n",
      "[200]\tvalid_0's rmse: 12.9011\tvalid_0's l2: 166.439\n",
      "[300]\tvalid_0's rmse: 12.8645\tvalid_0's l2: 165.496\n",
      "[400]\tvalid_0's rmse: 12.842\tvalid_0's l2: 164.916\n",
      "[500]\tvalid_0's rmse: 12.8208\tvalid_0's l2: 164.372\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "models = []\n",
    "\n",
    "for train_index, val_index in kf.split(x):\n",
    "    x_train, x_val = x[train_index], x[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**common_params)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_val, y_val)], eval_metric=\"rmse\", callbacks=[lgb.log_evaluation(100)])\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6786214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\repos\\class\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds = sum(model.predict(X_test) for model in models) / len(models)\n",
    "\n",
    "with open(\"submission_lgbm.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"id\", \"prediction\"])\n",
    "    for i, pred in enumerate(preds, start=750000):\n",
    "        writer.writerow([i, pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d863e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_plot = [\"Episode_Length_minutes\", \"Host_Popularity_percentage\", \n",
    "                    \"Guest_Popularity_percentage\", \"Listening_Time_minutes\", \"Number_of_Ads\"]\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features_to_plot, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[feature], kde=True)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df[features_to_plot].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
